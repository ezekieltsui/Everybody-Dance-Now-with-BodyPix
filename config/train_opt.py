checkpoints_dir = './checkpoints/'
dataroot = './data/target/'

# load_pretrain = './checkpoints/target/' # use this if you want to continue last training
label_nc = 25
load_pretrain = None
batchSize = 1
beta1 = 0.5
continue_train = False
data_type = 32
debug = False
display_freq = 640
display_winsize = 512
feat_num = 3
fineSize = 512
fine_size = 480
input_nc = 3
instance_feat = False
isTrain = True
label_feat = False
lambda_feat = 10.0
loadSize = 512
load_features = False
# load_pretrain = ''
lr = 0.0002
max_dataset_size = 100000
model = 'pix2pixHD'
nThreads = 0
n_blocks_global = 9
n_blocks_local = 3
n_clusters = 10
n_downsample_E = 4
n_downsample_global = 4
n_layers_D = 3
n_local_enhancers = 1
name = 'target'
ndf = 64
nef = 16
netG = 'global'
ngf = 64
niter = 20
niter_decay = 20
niter_fix_global = 0
no_flip = False
no_ganFeat_loss = False
no_html = False
no_instance = True
no_lsgan=False
no_vgg_loss = False
norm = 'instance'
num_D = 2
output_nc = 3
phase = 'train'
pool_size = 0
print_freq = 640
resize_or_crop = 'scale_width'
save_epoch_freq = 10
save_latest_freq = 640
serial_batches = False
tf_log = True
use_dropout = False
verbose = False
which_epoch = 'latest'
gpu_ids = [0]
